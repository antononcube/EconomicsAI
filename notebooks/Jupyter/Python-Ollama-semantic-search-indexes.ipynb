{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic search indexes with Ollama (Python)\n",
        "\n",
        "***...using RAG***\n",
        "\n",
        "Anton Antonov  \n",
        "January 2026\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "## Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook has the following workflow:\n",
        "\n",
        "1. Load packages:\n",
        "    - RAG packages (LangChain)\n",
        "    - Ollama embeddings\n",
        "    - Data display packages\n",
        "2. Ingest a set of text files\n",
        "    - Produce a corresponding data frame\n",
        "3. Summarize the data frame\n",
        "4. Prepare the documents for RAG\n",
        "5. Create a semantic search index for the texts\n",
        "    - Use batching to avoid large embedding calls\n",
        "    - Merge the partial indexes into a single [FAISS index](https://docs.langchain.com/oss/python/integrations/vectorstores/faiss)\n",
        "6. Export the vector database\n",
        "7. Verification:\n",
        "    - Import the vector database\n",
        "    - Run a sample retrieval\n",
        "    - Generate a LLM answer using the RAG result as context \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load general, LLM, RAG, and display packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import xdg\n",
        "from typing import List\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "#from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Display packages\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb9fa591",
      "metadata": {},
      "source": [
        "Create an embedding client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54adbae3",
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = OllamaEmbeddings(\n",
        "    model=\"nomic-embed-text\",\n",
        "    base_url=\"http://localhost:11434\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7b870fe",
      "metadata": {},
      "source": [
        "Ollama LLM model for queries processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "5af5f950",
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOllama(\n",
        "    model=\"gpt-oss:20b\",\n",
        "    base_url=\"http://localhost:11434\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27ac41a",
      "metadata": {},
      "source": [
        "### Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91846d4f",
      "metadata": {},
      "source": [
        "Preferred vector databases storage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "6f94a955",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_xdg_data_home_dir():\n",
        "    xdg_data_home = os.environ.get('XDG_DATA_HOME', os.path.expanduser('~/.local/share'))\n",
        "    target_dir = os.path.join(xdg_data_home, 'Python', 'LLM', 'SemanticSearch')\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "    return target_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "## Data ingestion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingesting text data...\n",
            "76 files\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['../../texts/DialogueWorks/Wolff-Hudson/-fCOefH-Fnw.txt',\n",
              " '../../texts/DialogueWorks/Wolff-Hudson/0lD_UrtPVpA.txt',\n",
              " '../../texts/DialogueWorks/Wolff-Hudson/2FKtZtjN_cA.txt',\n",
              " '../../texts/DialogueWorks/Wolff-Hudson/4G98DeCZcT8.txt',\n",
              " '../../texts/DialogueWorks/Wolff-Hudson/594yN8rxIJo.txt']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Ingesting text data...\")\n",
        "\n",
        "data_dir = os.path.expanduser(\"../../texts/DialogueWorks/Wolff-Hudson\")\n",
        "file_names = sorted(glob.glob(os.path.join(data_dir, \"*.txt\")))\n",
        "\n",
        "print(f\"{len(file_names)} files\")\n",
        "file_names[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read all text into a single list\n",
        "texts = []\n",
        "for path in file_names:\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        texts.append(file.read())\n",
        "\n",
        "basenames = [ re.sub(r'\\.txt$', '', os.path.basename(x)) for x in file_names]\n",
        "\n",
        "texts = dict(zip(basenames, texts))\n",
        "\n",
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "27f88019",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-fCOefH-Fnw</td>\n",
              "      <td>Hi everybody. Today is Thursday, June 26, 2025...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0lD_UrtPVpA</td>\n",
              "      <td>hi everybody today's th February 13 2025 and o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2FKtZtjN_cA</td>\n",
              "      <td>Hi everybody. Today is Thursday, June 12, 2025...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4G98DeCZcT8</td>\n",
              "      <td>Hi everybody. Today is Thursday, April 24th, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>594yN8rxIJo</td>\n",
              "      <td>hi everybody today is Thursday April 3r 25 and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>w--fsqQQQa0</td>\n",
              "      <td>hi everybody today is Thursday February 6th 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>wl8sBSx5lpI</td>\n",
              "      <td>hi everybody today is Wednesday November 27th ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>xJMbCi3cmQI</td>\n",
              "      <td>let's start with the SEO Summit in kakistan As...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>zHmzUl0HmPE</td>\n",
              "      <td>what are the impacts of sanctions on a country...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>zy2pInARtPY</td>\n",
              "      <td>Richard when you look at these new demonstrati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID                                               Text\n",
              "0   -fCOefH-Fnw  Hi everybody. Today is Thursday, June 26, 2025...\n",
              "1   0lD_UrtPVpA  hi everybody today's th February 13 2025 and o...\n",
              "2   2FKtZtjN_cA  Hi everybody. Today is Thursday, June 12, 2025...\n",
              "3   4G98DeCZcT8  Hi everybody. Today is Thursday, April 24th, 2...\n",
              "4   594yN8rxIJo  hi everybody today is Thursday April 3r 25 and...\n",
              "..          ...                                                ...\n",
              "71  w--fsqQQQa0  hi everybody today is Thursday February 6th 20...\n",
              "72  wl8sBSx5lpI  hi everybody today is Wednesday November 27th ...\n",
              "73  xJMbCi3cmQI  let's start with the SEO Summit in kakistan As...\n",
              "74  zHmzUl0HmPE  what are the impacts of sanctions on a country...\n",
              "75  zy2pInARtPY  Richard when you look at these new demonstrati...\n",
              "\n",
              "[76 rows x 2 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfTexts = pd.DataFrame([{\"ID\": k, \"Text\" : v} for (k, v) in texts.items()])\n",
        "dfTexts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summaries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5c0613",
      "metadata": {},
      "source": [
        "Basic character-length summary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ed82e226",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count       76.000000\n",
              "mean     40516.842105\n",
              "std      14227.287461\n",
              "min       6498.000000\n",
              "25%      31202.500000\n",
              "50%      41394.500000\n",
              "75%      49382.500000\n",
              "max      70363.000000\n",
              "Name: Text, dtype: float64"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Basic character-length summary for the text columns\n",
        "summary = (\n",
        "    dfTexts[\"Text\"]\n",
        "    .astype(str)\n",
        "    .map(len)\n",
        "    .describe()\n",
        ")\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "## Documents preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared 76 documents\n"
          ]
        }
      ],
      "source": [
        "# Map Record_ID to the main text column and filter short records\n",
        "min_chars = 100\n",
        "rows = dfTexts[[\"ID\", \"Text\"]].copy()\n",
        "rows[\"Text\"] = rows[\"Text\"].astype(str)\n",
        "rows = rows[rows[\"Text\"].str.len() >= min_chars]\n",
        "\n",
        "records = [\n",
        "    Document(\n",
        "        page_content=row.Text,\n",
        "        metadata={\"record_id\": row.ID},\n",
        "    )\n",
        "    for row in rows.itertuples(index=False)\n",
        "]\n",
        "\n",
        "print(f\"Prepared {len(records)} documents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Semantic indexes\n",
        "\n",
        "- Embedding very large batches can be slow or fail.\n",
        "- We create smaller FAISS indexes, then merge them into a single index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunked documents: 3646\n"
          ]
        }
      ],
      "source": [
        "# Split long texts into chunks for better recall\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150,\n",
        ")\n",
        "\n",
        "chunked_docs: List[Document] = []\n",
        "for doc in records:\n",
        "    chunked_docs.extend(text_splitter.split_documents([doc]))\n",
        "\n",
        "print(f\"Chunked documents: {len(chunked_docs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedded batch 1\n",
            "Embedded batch 2\n",
            "Embedded batch 3\n",
            "Embedded batch 4\n",
            "Total time: 47.2s\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1000\n",
        "faiss_index = None\n",
        "\n",
        "start = time.time()\n",
        "for i in range(0, len(chunked_docs), batch_size):\n",
        "    batch = chunked_docs[i : i + batch_size]\n",
        "    batch_index = FAISS.from_documents(batch, embeddings)\n",
        "    if faiss_index is None:\n",
        "        faiss_index = batch_index\n",
        "    else:\n",
        "        faiss_index.merge_from(batch_index)\n",
        "    print(f\"Embedded batch {i // batch_size + 1}\")\n",
        "\n",
        "print(f\"Total time: {time.time() - start:.1f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "## Export semantic index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "215a78ed",
      "metadata": {},
      "source": [
        "Persist the merged FAISS index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "export_dir = ensure_xdg_data_home_dir() + \"/EconomicsAI\"\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "faiss_index.save_local(export_dir)\n",
        "\n",
        "#export_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65ed4dbb",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Retrieval experiments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bd71d90",
      "metadata": {},
      "source": [
        "Import vector database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da9b6a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "export_dir = os.path.expanduser(\"~/.local/share/Python/LLM/SemanticSearch\") + \"/EconomicsAI\"\n",
        "vdb = FAISS.load_local(export_dir, embeddings, allow_dangerous_deserialization=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ac976bd",
      "metadata": {},
      "source": [
        "Search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "92458d59",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['JQ2P5yitPyE',\n",
              " 'v5CGEQrv0Lg',\n",
              " 'uS4ewq1R9ps',\n",
              " 'e5Ed7b1-LnY',\n",
              " 'WqwK3xdZe1A',\n",
              " 'loxwfNQw17o',\n",
              " 'pHOJ2ASlu80',\n",
              " 'v5CGEQrv0Lg',\n",
              " 'vU1uxkZUFb0',\n",
              " '4G98DeCZcT8']"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"how capitalism undermines itself\"\n",
        "rag_docs = vdb.similarity_search(query, k=10)\n",
        "\n",
        "#res = [(r.metadata.get(\"record_id\"), r.page_content[:200]) for r in results]\n",
        "res = [r.metadata.get(\"record_id\") for r in rag_docs]\n",
        "res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "51a6ac69",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This works but there is a built-in way of doing it.\n",
        "#df2 = dfTexts[dfTexts[\"ID\"].isin(res)]\n",
        "#text_chunks = list(df2[\"Text\"])\n",
        "\n",
        "text_chunks = [doc.page_content.strip() for doc in rag_docs if doc.page_content]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b50f8c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = PromptTemplate.from_template(\n",
        "    \"Summarize in a list with at most {number_of_items} points the content of this document chunks:\\n {doc_chunks}\"\n",
        ")\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "result = chain.invoke({\n",
        "    \"number_of_items\": 12, \n",
        "    \"doc_chunks\": \"\\n\\n\".join(text_chunks)\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "fd6664e2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Key points from the document:**\n",
              "\n",
              "1. **Capitalism produces both wealth and poverty** – it amplifies inequality while also generating large segments of the population in extreme poverty.  \n",
              "2. **Uneven development** – even within the same city, five miles apart can be the richest and the poorest places, illustrating the uneven spread of capitalistic gains.  \n",
              "3. **International agreements perpetuate the divide** – treaties, trade, and investment deals formalise the separation between rich and poor regions, reinforcing capital’s uneven expansion.  \n",
              "4. **Economic inequality breeds political manipulation** – as the wealthy minority outgrows the majority, it often uses its resources to corrupt or limit democratic institutions to protect its interests.  \n",
              "5. **Capitalism’s inherent instability** – the system is cyclical: sectors boom on credit, become over‑expanded, then crash or are forced back into equilibrium through government intervention.  \n",
              "6. **Critics highlight the lack of coordination** – decision‑making is fragmented among enterprises, leading to systemic crises unless corrected by state action.  \n",
              "7. **Marx’s duality of capitalism** – “capitalism is a constant producer and reproducer of great wealth … and great poverty”; the same mechanism that creates riches also creates misery.  \n",
              "8. **Unfulfilled promises** – capitalism has historically failed to deliver on the ideals of liberty, equality, fraternity, and democracy it initially promised.  \n",
              "9. **Capitalism itself blocks those ideals** – Marx argued that the very structure of capitalism prevents the realization of freedom, equality, and democracy.  \n",
              "10. **China’s hybrid model as a counterexample** – a powerful state coupled with a sizable private sector has achieved unprecedented growth, outperforming Western economies.  \n",
              "11. **Capitalism is not democratic** – its organizational logic (hierarchies, ownership concentration, profit maximisation) is fundamentally at odds with democratic decision‑making.  \n",
              "12. **Environmental contradictions** – capitalist pursuit of profit inevitably degrades the natural environment; these contradictions are built into the system and will recur when conditions change."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(result))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "SciPyCentric",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
