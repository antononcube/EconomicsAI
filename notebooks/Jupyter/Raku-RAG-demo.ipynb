{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raku RAG demo\n",
    "\n",
    "<span style=\"font-size: 16pt;\">... and </span>\n",
    "<span style=\"font-size: 16pt; font-style: italic;\">Semantic Nearest Neighbors Graph</span>\n",
    "\n",
    "Anton Antonov   \n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com)   \n",
    "[RakuForPrediction-book at GitHub](https://github.com/antononcube/RakuForPrediction-book)      \n",
    "September 2024 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The so called ***Retrieval Augmented Generation (RAG)*** functionalities of Large Language Models (LLMs) are demonstrated using semantic nearest neighbors graphs.\n",
    "\n",
    "Vector Databases (VDBs) made with the Raku package [\"LLM::RetrievalAugmentedGeneration\"](https://raku.land/zef:antononcube/LLM::RetrievalAugmentedGeneration) are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Semantic graph for words \n",
    "    - Select a set of words\n",
    "    - Find LLM embeddings for the those words\n",
    "    - Find nearest neighbor graph for the obtained vectors\n",
    "\n",
    "2. Nearest neighbor graph -- joined VDBs\n",
    "    - Ingest VDBs corresponding to (long) podcast interviews\n",
    "        - \"Modern Wisdom\" with [Eric Weinstein](https://en.wikipedia.org/wiki/Eric_Weinstein)\n",
    "        - Eclectic and long interviews (≈3.5 hours each)\n",
    "        - Heterogeneous content (wide variety of topics)\n",
    "        - *(Hence, suitable for semantic similarities demos)*\n",
    "    - Merge VDBs\n",
    "    - Make a corresponding semantic graph\n",
    "        - Nearest neighbor graph\n",
    "        - Connected components\n",
    "\n",
    "3. Nearest neighbor graph and RAG \n",
    "    - Create a semantic relationship graph for an interview\n",
    "    - LLM-derivation of summaries for top connected components\n",
    "    - Graph plot traces \n",
    "        - Using suitable graph tooltips\n",
    "    - Do a retrieval based LLM summary for a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use LLM::Configurations;\n",
    "use LLM::RetrievalAugmentedGeneration;\n",
    "use LLM::RetrievalAugmentedGeneration::VectorDatabase;\n",
    "\n",
    "use XDG::BaseDirectory :terms;\n",
    "\n",
    "use Data::Importers;\n",
    "use Data::Reshapers;\n",
    "use Data::Summarizers;\n",
    "use Math::Nearest;\n",
    "use Math::DistanceFunctions::Native;\n",
    "use Statistics::OutlierIdentifiers;\n",
    "\n",
    "use NativeCall;\n",
    "\n",
    "use Math::Nearest;\n",
    "use Graph;\n",
    "use JavaScript::D3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare the notebook to visualize with JavaScript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% javascript\n",
    "require.config({\n",
    "     paths: {\n",
    "     d3: 'https://d3js.org/d3.v7.min'\n",
    "}});\n",
    "\n",
    "require(['d3'], function(d3) {\n",
    "     console.log(d3);\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% js\n",
    "js-d3-list-line-plot(10.rand xx 40, background => 'none', stroke-width => 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set a collection of visualization variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my $title-color = 'Ivory';\n",
    "my $stroke-color = 'SlateGray';\n",
    "my $tooltip-color = 'LightBlue';\n",
    "my $tooltip-background-color = 'none';\n",
    "my $background = '1F1F1F';\n",
    "my $color-scheme = 'schemeTableau10';\n",
    "my $edge-thickness = 3;\n",
    "my $vertex-size = 6;\n",
    "my $mmd-theme = q:to/END/;\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'forest',\n",
    "    'themeVariables': {\n",
    "      'lineColor': 'Ivory'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "END\n",
    "my %force = collision => {iterations => 0, radius => 10},link => {distance => 180};\n",
    "my %force2 = charge => {strength => -30, iterations => 4}, collision => {radius => 50, iterations => 4}, link => {distance => 30};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Ingest vector databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest vector database from the default directory and show a summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% html\n",
    "my @field-names = <id name item-count dimension version llm-service llm-embedding-model created>;\n",
    "\n",
    "vector-database-objects(f=>'hash', :flat)\n",
    "\n",
    "==> { $_.map({ $_<created> = $_<file>.IO.created.DateTime.Str.subst('T',' ').substr(^19); $_}).sort(*<created>).reverse }()\n",
    "==> to-html(:@field-names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get specific databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my @vdbs = vector-database-objects(f=>'hash', :flat).grep({ $_<name> ∈ <No833 No747> && $_<llm-service> eq 'gemini' }).map({ create-vector-database(file => $_<file>) })\n",
    "\n",
    "my @vdbs = vector-database-objects(f=>'hash', :flat).grep({ $_<id> ∈ <a840beb1-b0fa-49af-b206-25f4644daae0> }).map({ create-vector-database(file => $_<file>) })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".say for @vdbs.head.vectors.pick(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% html\n",
    "@vdbs.head.items.pick(3).map({ <key value> Z=> $_.kv })».Hash.Array \n",
    "==> to-html(field-names => <key value>, align => 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Combined databases graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the selected databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my $vdbObj2 = vector-database-join(@vdbs)\n",
    "my $vdbObj2 = @vdbs.head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a nearest neighbors graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @edges2 = nearest-neighbor-graph($vdbObj2.vectors.pairs, 1, method => 'Scan', distance-function => &euclidean-distance, format => 'raku');\n",
    "\n",
    "my $gr2 = Graph.new(@edges2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @comps2 = $gr2.connected-components.sort(-*.elems).head(8);\n",
    "\n",
    "@comps2.elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% js\n",
    "@edges2\n",
    "==> js-d3-graph-plot(\n",
    "        :$background,\n",
    "        highlight => @comps2.map({[|$_, |$gr2.subgraph($_).edges]}),\n",
    "        vertex-label-color => 'none',\n",
    "        edge-thickness => 2,\n",
    "        vertex-size => 4,\n",
    "        vertex-color => 'Blue',\n",
    "        width => 1100,\n",
    "        height => 950,\n",
    "        edge-color => 'Gray',\n",
    "        vertex-color => 'DarkGray',\n",
    "        #force => {charge => {strength => -3, iterations => 4}, collision => {radius => 14, iterations => 4}, link => {distance => 1};}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Nearest neighbors for a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my $query = 'What are the problems with the newly introduced tariffs? Give a list of bullet points.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same configuration is used for the vector database creation\n",
    "my $conf = llm-configuration(\"Gemini\");\n",
    "\n",
    "$conf.Hash.elems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a query vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my $vec = llm-embedding($query, e => $conf).head».Num.Array;\n",
    "\n",
    "deduce-type($vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @nns = |$vdbObj2.nearest($vec, 6).flat(:hammer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the corresponding \"paragraphs\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @paragraphs = $vdbObj2.items{|@nns};\n",
    "\n",
    ".say for @paragraphs».&text-stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate LLM based answer using the nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% markdown\n",
    "\n",
    "llm-synthesize([ \n",
    "    \"Summarize the following text into a list of three-four points, each with no more than 8 words:\",\n",
    "    $vdbObj.items{|@nns.sort}.join(\" \"),\n",
    "], e => $conf4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% markdown\n",
    "\n",
    "llm-synthesize([ \n",
    "    \"Answer the inquiry:\",\n",
    "    $query,\n",
    "    \"using the following text:\",\n",
    "    $vdbObj.items{|@nns.sort}.join(\" \"),\n",
    "], e => $conf4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm-prompt-data(/:i SophisticatedFeedback /)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Extract wisdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my $res = llm-synthesize([ \n",
    "    llm-prompt('ExtractArticleWisdom')(),\n",
    "    $vdbObj.items{|@nns.sort}.join(\" \"),\n",
    "], e => $conf4o);\n",
    "\n",
    "$res.&text-stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% markdown\n",
    "$res.subst( / ^^ '## '/, '### '):g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles\n",
    "\n",
    "[AA1] Anton Antonov, \n",
    "[\"Outlier detection in a list of numbers\"](https://rakuforprediction.wordpress.com/2022/05/29/outlier-detection-in-a-list-of-numbers/),\n",
    "(2022),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[WWW::OpenAI Raku package](https://github.com/antononcube/Raku-WWW-OpenAI),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[WWW::PaLM Raku package](https://github.com/antononcube/Raku-WWW-PaLM),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[LLM::Functions Raku package](https://github.com/antononcube/Raku-LLM-Functions),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp4] Anton Antonov,\n",
    "[LLM::Prompts Raku package](https://github.com/antononcube/Raku-LLM-Prompts),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp5] Anton Antonov,\n",
    "[ML::FindTextualAnswer Raku package](https://github.com/antononcube/Raku-ML-FindTextualAnswer),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp6] Anton Antonov,\n",
    "[Math::Nearest Raku package](https://github.com/antononcube/Raku-Math-Nearest),\n",
    "(2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp7] Anton Antonov,\n",
    "[Math::DistanceFunctions Raku package](https://github.com/antononcube/Raku-Math-DistanceFunctions),\n",
    "(2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp8] Anton Antonov,\n",
    "[Statistics::OutlierIdentifiers Raku package](https://github.com/antononcube/Raku-Statistics-OutlierIdentifiers),\n",
    "(2022),\n",
    "[GitHub/antononcube](https://github.com/antononcube)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos\n",
    "\n",
    "[AAv1] Anton Antonov,\n",
    "[\"Raku RAG demo\"](https://www.youtube.com/watch?v=JHO2Wk1b-Og),\n",
    "(2024),\n",
    "[YouTube/AAA4prediction](https://www.youtube.com/@AAA4prediction).\n",
    "\n",
    "[CWv1] Chris Williamson,\n",
    "[\"Eric Weinstein - Why Does The Modern World Make No Sense? (4K)\"](https://www.youtube.com/watch?v=p_swB_KS8Hw),\n",
    "(2024),\n",
    "[YouTube/@ChrisWillx](https://www.youtube.com/@ChrisWillx).   \n",
    "([transcript](https://podscripts.co/podcasts/modern-wisdom/747-eric-weinstein-why-does-the-modern-world-make-no-sense).)\n",
    "\n",
    "[CWv2] Chris Williamson,\n",
    "[\"Eric Weinstein - Are We On The Brink Of A Revolution? (4K)\"](https://www.youtube.com/watch?v=PYRYXhU4kxM),\n",
    "(2024),\n",
    "[YouTube/@ChrisWillx](https://www.youtube.com/@ChrisWillx).   \n",
    "([transcript](https://podscripts.co/podcasts/modern-wisdom/833-eric-weinstein-are-we-on-the-brink-of-a-revolution).)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
